{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, 9, 9], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/250.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0\n",
    "\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01458002, -0.04311134,  0.05076292, ..., -0.04930744,\n",
       "        -0.04483645, -0.05507614],\n",
       "       [-0.0712176 , -0.0015389 ,  0.0644761 , ...,  0.07258993,\n",
       "        -0.05103677,  0.04920105],\n",
       "       [-0.00629713, -0.03819362, -0.00193912, ...,  0.06870107,\n",
       "         0.03022622, -0.06050261],\n",
       "       ...,\n",
       "       [ 0.03054941,  0.06118892,  0.03731606, ..., -0.03828354,\n",
       "        -0.03573275, -0.00955287],\n",
       "       [ 0.0465321 ,  0.02805855,  0.03715704, ..., -0.02111965,\n",
       "         0.06186396,  0.05215184],\n",
       "       [ 0.04157574,  0.05333932, -0.01838977, ..., -0.06404218,\n",
       "        -0.0015801 , -0.0258346 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7065 - accuracy: 0.7695 - val_loss: 0.5253 - val_accuracy: 0.8204\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4878 - accuracy: 0.8287 - val_loss: 0.4408 - val_accuracy: 0.8460\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4430 - accuracy: 0.8439 - val_loss: 0.5368 - val_accuracy: 0.7988\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4158 - accuracy: 0.8543 - val_loss: 0.3967 - val_accuracy: 0.8646\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3972 - accuracy: 0.8605 - val_loss: 0.3805 - val_accuracy: 0.8686\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3781 - accuracy: 0.8666 - val_loss: 0.3767 - val_accuracy: 0.8706\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3660 - accuracy: 0.8710 - val_loss: 0.3641 - val_accuracy: 0.8744\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3545 - accuracy: 0.8734 - val_loss: 0.3961 - val_accuracy: 0.8560\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3440 - accuracy: 0.8777 - val_loss: 0.3543 - val_accuracy: 0.8728\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3347 - accuracy: 0.8805 - val_loss: 0.3574 - val_accuracy: 0.8696\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3266 - accuracy: 0.8826 - val_loss: 0.3467 - val_accuracy: 0.8780\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3169 - accuracy: 0.8857 - val_loss: 0.3355 - val_accuracy: 0.8796\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3100 - accuracy: 0.8889 - val_loss: 0.3325 - val_accuracy: 0.8816\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3041 - accuracy: 0.8898 - val_loss: 0.3540 - val_accuracy: 0.8696\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2961 - accuracy: 0.8939 - val_loss: 0.3303 - val_accuracy: 0.8808\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2911 - accuracy: 0.8968 - val_loss: 0.3147 - val_accuracy: 0.8858\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2856 - accuracy: 0.8965 - val_loss: 0.3572 - val_accuracy: 0.8740\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2798 - accuracy: 0.8992 - val_loss: 0.3148 - val_accuracy: 0.8886\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2746 - accuracy: 0.9004 - val_loss: 0.3111 - val_accuracy: 0.8906\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2691 - accuracy: 0.9029 - val_loss: 0.3347 - val_accuracy: 0.8804\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2646 - accuracy: 0.9049 - val_loss: 0.3080 - val_accuracy: 0.8902\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2597 - accuracy: 0.9054 - val_loss: 0.2989 - val_accuracy: 0.8928\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2548 - accuracy: 0.9078 - val_loss: 0.3040 - val_accuracy: 0.8898\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2506 - accuracy: 0.9094 - val_loss: 0.3078 - val_accuracy: 0.8866\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2464 - accuracy: 0.9110 - val_loss: 0.3022 - val_accuracy: 0.8938\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2420 - accuracy: 0.9123 - val_loss: 0.3091 - val_accuracy: 0.8908\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2391 - accuracy: 0.9129 - val_loss: 0.3032 - val_accuracy: 0.8910\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2350 - accuracy: 0.9153 - val_loss: 0.3082 - val_accuracy: 0.8858\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2307 - accuracy: 0.9173 - val_loss: 0.3076 - val_accuracy: 0.8902\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2272 - accuracy: 0.9180 - val_loss: 0.3156 - val_accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=30, validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2218 - accuracy: 0.9199 - val_loss: 0.2949 - val_accuracy: 0.8912\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2189 - accuracy: 0.9218 - val_loss: 0.2911 - val_accuracy: 0.8958\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2153 - accuracy: 0.9217 - val_loss: 0.3778 - val_accuracy: 0.8652\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2121 - accuracy: 0.9241 - val_loss: 0.2979 - val_accuracy: 0.8936\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2098 - accuracy: 0.9249 - val_loss: 0.2866 - val_accuracy: 0.8988\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2045 - accuracy: 0.9265 - val_loss: 0.3089 - val_accuracy: 0.8884\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2023 - accuracy: 0.9281 - val_loss: 0.2990 - val_accuracy: 0.8950\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1991 - accuracy: 0.9287 - val_loss: 0.3144 - val_accuracy: 0.8868\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1955 - accuracy: 0.9300 - val_loss: 0.2977 - val_accuracy: 0.8928\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1918 - accuracy: 0.9313 - val_loss: 0.2958 - val_accuracy: 0.8956\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1897 - accuracy: 0.9321 - val_loss: 0.2917 - val_accuracy: 0.8936\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1848 - accuracy: 0.9341 - val_loss: 0.3100 - val_accuracy: 0.8882\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1833 - accuracy: 0.9347 - val_loss: 0.2937 - val_accuracy: 0.8980\n",
      "Epoch 14/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1807 - accuracy: 0.9348 - val_loss: 0.3181 - val_accuracy: 0.8866\n",
      "Epoch 15/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1770 - accuracy: 0.9368 - val_loss: 0.3052 - val_accuracy: 0.8932\n",
      "Epoch 16/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1747 - accuracy: 0.9377 - val_loss: 0.2959 - val_accuracy: 0.8930\n",
      "Epoch 17/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1720 - accuracy: 0.9391 - val_loss: 0.3398 - val_accuracy: 0.8862\n",
      "Epoch 18/40\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.93 - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9398 - val_loss: 0.2902 - val_accuracy: 0.9006\n",
      "Epoch 19/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1664 - accuracy: 0.9409 - val_loss: 0.2949 - val_accuracy: 0.8978\n",
      "Epoch 20/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1637 - accuracy: 0.9418 - val_loss: 0.3206 - val_accuracy: 0.8892\n",
      "Epoch 21/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1615 - accuracy: 0.9429 - val_loss: 0.2990 - val_accuracy: 0.8952\n",
      "Epoch 22/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1588 - accuracy: 0.9428 - val_loss: 0.2959 - val_accuracy: 0.8980\n",
      "Epoch 23/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1559 - accuracy: 0.9442 - val_loss: 0.2954 - val_accuracy: 0.8964\n",
      "Epoch 24/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1539 - accuracy: 0.9454 - val_loss: 0.3100 - val_accuracy: 0.8926\n",
      "Epoch 25/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1505 - accuracy: 0.9468 - val_loss: 0.2993 - val_accuracy: 0.8958\n",
      "Epoch 26/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1486 - accuracy: 0.9470 - val_loss: 0.3168 - val_accuracy: 0.8926\n",
      "Epoch 27/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1466 - accuracy: 0.9484 - val_loss: 0.3266 - val_accuracy: 0.8940\n",
      "Epoch 28/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1443 - accuracy: 0.9483 - val_loss: 0.3084 - val_accuracy: 0.8952\n",
      "Epoch 29/40\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1415 - accuracy: 0.9491 - val_loss: 0.3144 - val_accuracy: 0.8930\n",
      "Epoch 30/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1391 - accuracy: 0.9517 - val_loss: 0.3383 - val_accuracy: 0.8910\n",
      "Epoch 31/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1368 - accuracy: 0.9508 - val_loss: 0.3037 - val_accuracy: 0.8968\n",
      "Epoch 32/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1349 - accuracy: 0.9525 - val_loss: 0.3256 - val_accuracy: 0.8994\n",
      "Epoch 33/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1330 - accuracy: 0.9536 - val_loss: 0.3130 - val_accuracy: 0.8938\n",
      "Epoch 34/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1301 - accuracy: 0.9538 - val_loss: 0.3152 - val_accuracy: 0.8974\n",
      "Epoch 35/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1273 - accuracy: 0.9562 - val_loss: 0.3003 - val_accuracy: 0.8972\n",
      "Epoch 36/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1263 - accuracy: 0.9556 - val_loss: 0.3252 - val_accuracy: 0.8978\n",
      "Epoch 37/40\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1232 - accuracy: 0.9564 - val_loss: 0.3148 - val_accuracy: 0.8964\n",
      "Epoch 38/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1204 - accuracy: 0.9574 - val_loss: 0.3076 - val_accuracy: 0.8968\n",
      "Epoch 39/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1212 - accuracy: 0.9574 - val_loss: 0.3262 - val_accuracy: 0.8990\n",
      "Epoch 40/40\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1179 - accuracy: 0.9592 - val_loss: 0.3149 - val_accuracy: 0.9010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=40, validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 930us/step - loss: 0.3409 - accuracy: 0.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3408835530281067, 0.8938999772071838]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-c6f2bcc1d134>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict_classes(X_new)\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 800us/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 843us/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 593us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3885664],\n",
       "       [1.6792021],\n",
       "       [3.1022797]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15780104, -0.28673138, -0.49550877, -0.16618097, -0.02946012,\n",
       "         0.38899735,  0.19374821,  0.2870474 ],\n",
       "       [-0.7125531 ,  0.10880952, -0.16332973,  0.20164652,  0.12842117,\n",
       "        -0.11818174, -0.23725261,  0.06215231],\n",
       "       [-0.2156101 ,  1.8491895 , -0.57982788,  0.18528489, -0.10429403,\n",
       "        -0.67694905,  1.00890193, -1.4271529 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[hidden2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30)                930       \n",
      "=================================================================\n",
      "Total params: 1,200\n",
      "Trainable params: 1,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 5.0757 - val_loss: 6.0348\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 897us/step - loss: 4.8836 - val_loss: 5.9661\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 842us/step - loss: 4.6563 - val_loss: 5.8784\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 835us/step - loss: 4.3923 - val_loss: 5.7594\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 857us/step - loss: 4.0874 - val_loss: 5.6001\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 896us/step - loss: 3.7462 - val_loss: 5.4150\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 834us/step - loss: 3.3825 - val_loss: 5.2285\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 841us/step - loss: 3.0007 - val_loss: 4.9792\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 760us/step - loss: 2.6054 - val_loss: 4.6763\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 835us/step - loss: 2.2320 - val_loss: 4.3357\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 893us/step - loss: 1.9076 - val_loss: 3.9434\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 1.6448 - val_loss: 3.5674\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 875us/step - loss: 1.4381 - val_loss: 3.2010\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 824us/step - loss: 1.2735 - val_loss: 2.8563\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 815us/step - loss: 1.1521 - val_loss: 2.5501\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 903us/step - loss: 1.0669 - val_loss: 2.2836\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 853us/step - loss: 1.0068 - val_loss: 2.0540\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.9631 - val_loss: 1.8587\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.9301 - val_loss: 1.6920\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.9041 - val_loss: 1.5518\n",
      "162/162 [==============================] - 0s 609us/step - loss: 0.8873\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling multiple inputs A and B in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0090 - val_loss: 0.9850\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.7896 - val_loss: 0.7180\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.6514 - val_loss: 0.6402\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.5991 - val_loss: 0.5778\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.5671 - val_loss: 0.5449\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.5423 - val_loss: 0.5190\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.5228 - val_loss: 0.5011\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.5073 - val_loss: 0.4808\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.4945 - val_loss: 0.4661\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.4841 - val_loss: 0.4553\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 952us/step - loss: 0.4758 - val_loss: 0.4457\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.4687 - val_loss: 0.4377\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.4627 - val_loss: 0.4322\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.4579 - val_loss: 0.4273\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4536 - val_loss: 0.4230\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.4500 - val_loss: 0.4185\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.4466 - val_loss: 0.4177\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.4441 - val_loss: 0.4169\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.4409 - val_loss: 0.4134\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.4386 - val_loss: 0.4224\n",
      "162/162 [==============================] - 0s 651us/step - loss: 0.4297\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/363 [..............................] - ETA: 0s - loss: 5.7342 - main_output_loss: 5.5741 - aux_output_loss: 7.1751WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2680 - main_output_loss: 1.9510 - aux_output_loss: 5.1214 - val_loss: 2.7346 - val_main_output_loss: 2.1457 - val_aux_output_loss: 8.0346\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0709 - main_output_loss: 0.8465 - aux_output_loss: 3.0910 - val_loss: 1.5914 - val_main_output_loss: 0.8960 - val_aux_output_loss: 7.8500\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8526 - main_output_loss: 0.7034 - aux_output_loss: 2.1957 - val_loss: 1.2902 - val_main_output_loss: 0.6649 - val_aux_output_loss: 6.9176\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7558 - main_output_loss: 0.6404 - aux_output_loss: 1.7942 - val_loss: 1.1200 - val_main_output_loss: 0.6066 - val_aux_output_loss: 5.7407\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6982 - main_output_loss: 0.5992 - aux_output_loss: 1.5896 - val_loss: 0.9833 - val_main_output_loss: 0.5615 - val_aux_output_loss: 4.7794\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6574 - main_output_loss: 0.5669 - aux_output_loss: 1.4721 - val_loss: 0.8677 - val_main_output_loss: 0.5297 - val_aux_output_loss: 3.9097\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6254 - main_output_loss: 0.5402 - aux_output_loss: 1.3918 - val_loss: 0.7787 - val_main_output_loss: 0.5055 - val_aux_output_loss: 3.2383\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6002 - main_output_loss: 0.5186 - aux_output_loss: 1.3346 - val_loss: 0.7052 - val_main_output_loss: 0.4850 - val_aux_output_loss: 2.6866\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5792 - main_output_loss: 0.5004 - aux_output_loss: 1.2885 - val_loss: 0.6510 - val_main_output_loss: 0.4694 - val_aux_output_loss: 2.2860\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5624 - main_output_loss: 0.4860 - aux_output_loss: 1.2507 - val_loss: 0.6120 - val_main_output_loss: 0.4594 - val_aux_output_loss: 1.9857\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5492 - main_output_loss: 0.4748 - aux_output_loss: 1.2187 - val_loss: 0.5858 - val_main_output_loss: 0.4553 - val_aux_output_loss: 1.7601\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5385 - main_output_loss: 0.4661 - aux_output_loss: 1.1900 - val_loss: 0.5600 - val_main_output_loss: 0.4461 - val_aux_output_loss: 1.5852\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5297 - main_output_loss: 0.4593 - aux_output_loss: 1.1639 - val_loss: 0.5469 - val_main_output_loss: 0.4467 - val_aux_output_loss: 1.4489\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5224 - main_output_loss: 0.4538 - aux_output_loss: 1.1393 - val_loss: 0.5355 - val_main_output_loss: 0.4452 - val_aux_output_loss: 1.3485\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5164 - main_output_loss: 0.4496 - aux_output_loss: 1.1168 - val_loss: 0.5250 - val_main_output_loss: 0.4424 - val_aux_output_loss: 1.2683\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5112 - main_output_loss: 0.4464 - aux_output_loss: 1.0948 - val_loss: 0.5162 - val_main_output_loss: 0.4401 - val_aux_output_loss: 1.2009\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5072 - main_output_loss: 0.4442 - aux_output_loss: 1.0744 - val_loss: 0.5111 - val_main_output_loss: 0.4403 - val_aux_output_loss: 1.1488\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5030 - main_output_loss: 0.4418 - aux_output_loss: 1.0545 - val_loss: 0.5101 - val_main_output_loss: 0.4437 - val_aux_output_loss: 1.1072\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4988 - main_output_loss: 0.4392 - aux_output_loss: 1.0355 - val_loss: 0.5025 - val_main_output_loss: 0.4395 - val_aux_output_loss: 1.0689\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4961 - main_output_loss: 0.4382 - aux_output_loss: 1.0178 - val_loss: 0.5110 - val_main_output_loss: 0.4522 - val_aux_output_loss: 1.0409\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 739us/step - loss: 0.4880 - main_output_loss: 0.4318 - aux_output_loss: 0.9943\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CEA351B280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35456353],\n",
       "       [2.0352635 ],\n",
       "       [3.1440048 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0930555],\n",
       "       [1.9890296],\n",
       "       [2.4363194]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1cea1fe3c40>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 598us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4393 - val_loss: 0.4110\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.4315 - val_loss: 0.4266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.3996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.3939\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.3889\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3746\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 0.3923 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3897 - val_loss: 0.3661\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3631\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3851 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3625\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3592\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3563\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3535\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 933us/step - loss: 0.3750 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3512\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3715 - val_loss: 0.3699\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3476\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3685 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3671 - val_loss: 0.3527\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3658 - val_loss: 0.3700\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3635 - val_loss: 0.3592\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3625 - val_loss: 0.3521\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.3613 - val_loss: 0.3626\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3431\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.3589 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3374\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.3572 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3563 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.3546 - val_loss: 0.3573\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.3538 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3530 - val_loss: 0.3425\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.3523 - val_loss: 0.3369\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3515 - val_loss: 0.3515\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3511 - val_loss: 0.3426\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3500 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 873us/step - loss: 0.3496 - val_loss: 0.3564\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3481 - val_loss: 0.3457\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3478 - val_loss: 0.3433\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.3471 - val_loss: 0.3659\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3286\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3268\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3454 - val_loss: 0.3439\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3263\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3444 - val_loss: 0.3910\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3439 - val_loss: 0.3275\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3435 - val_loss: 0.3561\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3423 - val_loss: 0.3242\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3419 - val_loss: 0.3765\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.3417 - val_loss: 0.3289\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3410 - val_loss: 0.3502\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3456\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3402 - val_loss: 0.3445\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3392 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3387 - val_loss: 0.3351\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3383 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3376 - val_loss: 0.3566\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.3374 - val_loss: 0.3257\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.3370 - val_loss: 0.3348\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3365 - val_loss: 0.3560\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3583\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3357 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3203\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3350 - val_loss: 0.3840\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3347 - val_loss: 0.3233\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.3342 - val_loss: 0.3476\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3338 - val_loss: 0.3407\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3335 - val_loss: 0.3462\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3332 - val_loss: 0.3347\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 886us/step - loss: 0.3329 - val_loss: 0.3354\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 952us/step - loss: 0.3324 - val_loss: 0.3274\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3167\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3317 - val_loss: 0.3280\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3312 - val_loss: 0.3634\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3310 - val_loss: 0.3176\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3305 - val_loss: 0.3529\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.3299 - val_loss: 0.3258\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3294 - val_loss: 0.3630\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3296 - val_loss: 0.3376\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3291 - val_loss: 0.3211\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3287 - val_loss: 0.3456\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3285 - val_loss: 0.3158\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.3281 - val_loss: 0.3409\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3276 - val_loss: 0.3379\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3273 - val_loss: 0.3213\n",
      "162/162 [==============================] - 0s 604us/step - loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/363 [=======================>......] - ETA: 0s - loss: 0.3305\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.3302 - val_loss: 0.3556\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 0.5308WARNING:tensorflow:From D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 2:23 - loss: 0.3876WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0405s vs `on_train_batch_end` time: 0.7424s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3300 - val_loss: 0.3201\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.3557\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3227\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.3160\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.3307\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.3198\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3173\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3186\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3352\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3234\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3116\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 0.3749\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.3120\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3156\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3418\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3228\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.3629\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.3108\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3118\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3701\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3109\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 0.4214\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.3643\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4025\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3231 - val_loss: 0.3085\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3905\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3468\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3932\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3082\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3749\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
