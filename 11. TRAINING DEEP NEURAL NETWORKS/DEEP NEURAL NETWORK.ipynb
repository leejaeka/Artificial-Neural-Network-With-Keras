{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"elu\",\n",
    "                                 kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 60s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 94.1493 - accuracy: 0.0312WARNING:tensorflow:From D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 12:09 - loss: 85.4689 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0504s vs `on_train_batch_end` time: 0.9289s). Check your callbacks.\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 3.8377 - accuracy: 0.1703 - val_loss: 2.1542 - val_accuracy: 0.2208\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 2.0217 - accuracy: 0.2626 - val_loss: 1.9793 - val_accuracy: 0.2714\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.9076 - accuracy: 0.3058 - val_loss: 2.0064 - val_accuracy: 0.2722\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.8296 - accuracy: 0.3327 - val_loss: 1.8439 - val_accuracy: 0.3254\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7690 - accuracy: 0.3583 - val_loss: 1.7254 - val_accuracy: 0.3738\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7251 - accuracy: 0.3726 - val_loss: 1.6926 - val_accuracy: 0.3918\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6829 - accuracy: 0.3904 - val_loss: 1.7570 - val_accuracy: 0.3476\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6490 - accuracy: 0.4052 - val_loss: 1.6844 - val_accuracy: 0.3930\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6217 - accuracy: 0.4164 - val_loss: 1.7064 - val_accuracy: 0.3876\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5971 - accuracy: 0.4231 - val_loss: 1.6719 - val_accuracy: 0.4044\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5775 - accuracy: 0.4306 - val_loss: 1.6001 - val_accuracy: 0.4338\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5544 - accuracy: 0.4407 - val_loss: 1.6107 - val_accuracy: 0.4282\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5367 - accuracy: 0.4468 - val_loss: 1.5776 - val_accuracy: 0.4304\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5155 - accuracy: 0.4519 - val_loss: 1.5778 - val_accuracy: 0.4350\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5008 - accuracy: 0.4582 - val_loss: 1.5884 - val_accuracy: 0.4308\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4836 - accuracy: 0.4679 - val_loss: 1.5426 - val_accuracy: 0.4410\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4683 - accuracy: 0.4719 - val_loss: 1.5799 - val_accuracy: 0.4356\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4545 - accuracy: 0.4770 - val_loss: 1.5355 - val_accuracy: 0.4520\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4400 - accuracy: 0.4809 - val_loss: 1.5148 - val_accuracy: 0.4544\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4273 - accuracy: 0.4857 - val_loss: 1.5253 - val_accuracy: 0.4532\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4194 - accuracy: 0.4914 - val_loss: 1.5057 - val_accuracy: 0.4640\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4041 - accuracy: 0.4938 - val_loss: 1.5554 - val_accuracy: 0.4430\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3929 - accuracy: 0.4982 - val_loss: 1.5470 - val_accuracy: 0.4442\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3814 - accuracy: 0.5027 - val_loss: 1.4994 - val_accuracy: 0.4670\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3707 - accuracy: 0.5090 - val_loss: 1.5299 - val_accuracy: 0.4516\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.3582 - accuracy: 0.5121 - val_loss: 1.4972 - val_accuracy: 0.4656\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3519 - accuracy: 0.5128 - val_loss: 1.4866 - val_accuracy: 0.4728\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3391 - accuracy: 0.5189 - val_loss: 1.5069 - val_accuracy: 0.4618\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3326 - accuracy: 0.5220 - val_loss: 1.5152 - val_accuracy: 0.4608\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3209 - accuracy: 0.5259 - val_loss: 1.5189 - val_accuracy: 0.4526\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3109 - accuracy: 0.5292 - val_loss: 1.5173 - val_accuracy: 0.4602\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3026 - accuracy: 0.5328 - val_loss: 1.5096 - val_accuracy: 0.4632\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2950 - accuracy: 0.5336 - val_loss: 1.4978 - val_accuracy: 0.4674\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2855 - accuracy: 0.5369 - val_loss: 1.5261 - val_accuracy: 0.4640\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2764 - accuracy: 0.5395 - val_loss: 1.5145 - val_accuracy: 0.4642\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2693 - accuracy: 0.5435 - val_loss: 1.5084 - val_accuracy: 0.4750\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.2596 - accuracy: 0.5478 - val_loss: 1.4722 - val_accuracy: 0.4862\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2489 - accuracy: 0.5509 - val_loss: 1.4863 - val_accuracy: 0.4776\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2456 - accuracy: 0.5534 - val_loss: 1.4937 - val_accuracy: 0.4832\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2334 - accuracy: 0.5580 - val_loss: 1.5111 - val_accuracy: 0.4772\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2264 - accuracy: 0.5593 - val_loss: 1.5029 - val_accuracy: 0.4826\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2199 - accuracy: 0.5618 - val_loss: 1.5042 - val_accuracy: 0.4694\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2130 - accuracy: 0.5655 - val_loss: 1.5438 - val_accuracy: 0.4684\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2011 - accuracy: 0.5683 - val_loss: 1.5018 - val_accuracy: 0.4878\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1961 - accuracy: 0.5690 - val_loss: 1.5070 - val_accuracy: 0.4848\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1927 - accuracy: 0.5715 - val_loss: 1.5067 - val_accuracy: 0.4832\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1863 - accuracy: 0.5760 - val_loss: 1.5265 - val_accuracy: 0.4810\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1757 - accuracy: 0.5774 - val_loss: 1.5086 - val_accuracy: 0.4750\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.1695 - accuracy: 0.5809 - val_loss: 1.5260 - val_accuracy: 0.4686\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1597 - accuracy: 0.5838 - val_loss: 1.5169 - val_accuracy: 0.4788\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1563 - accuracy: 0.5835 - val_loss: 1.5068 - val_accuracy: 0.4840\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1480 - accuracy: 0.5871 - val_loss: 1.5026 - val_accuracy: 0.4872\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1423 - accuracy: 0.5897 - val_loss: 1.5449 - val_accuracy: 0.4762\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1362 - accuracy: 0.5894 - val_loss: 1.5422 - val_accuracy: 0.4774\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1286 - accuracy: 0.5966 - val_loss: 1.5464 - val_accuracy: 0.4852\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1208 - accuracy: 0.5977 - val_loss: 1.5562 - val_accuracy: 0.4730\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1137 - accuracy: 0.6001 - val_loss: 1.5519 - val_accuracy: 0.4780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a920511f40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8868), started 0:16:26 ago. (Use '!kill 8868' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c425c3934a7f3848\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c425c3934a7f3848\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Batch Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 1:48:56 - loss: 2.8736 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 9.2777s). Check your callbacks.\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.8453 - accuracy: 0.3397 - val_loss: 1.7025 - val_accuracy: 0.3852\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6671 - accuracy: 0.4059 - val_loss: 1.5991 - val_accuracy: 0.4294\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5975 - accuracy: 0.4339 - val_loss: 1.5168 - val_accuracy: 0.4498\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5516 - accuracy: 0.4485 - val_loss: 1.5073 - val_accuracy: 0.4598\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5031 - accuracy: 0.4664 - val_loss: 1.4785 - val_accuracy: 0.4712\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4681 - accuracy: 0.4752 - val_loss: 1.4416 - val_accuracy: 0.4894\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.4334 - accuracy: 0.4932 - val_loss: 1.4181 - val_accuracy: 0.5026\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.4054 - accuracy: 0.5020 - val_loss: 1.3964 - val_accuracy: 0.5040\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3792 - accuracy: 0.5107 - val_loss: 1.3668 - val_accuracy: 0.5082\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3564 - accuracy: 0.5198 - val_loss: 1.3646 - val_accuracy: 0.5086\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3374 - accuracy: 0.5246 - val_loss: 1.3792 - val_accuracy: 0.5164\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3160 - accuracy: 0.5337 - val_loss: 1.3294 - val_accuracy: 0.5240\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2953 - accuracy: 0.5432 - val_loss: 1.3399 - val_accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2776 - accuracy: 0.5498 - val_loss: 1.3421 - val_accuracy: 0.5262\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2663 - accuracy: 0.5537 - val_loss: 1.3499 - val_accuracy: 0.5196\n",
      "Epoch 16/100\n",
      " 465/1407 [========>.....................] - ETA: 9s - loss: 1.2362 - accuracy: 0.5629"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes \n",
    "# (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of \n",
    "# dense layers, etc.).\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
